% resume template adapted from Aras Güngöre

\documentclass[letterpaper,11pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[dvipsnames]{xcolor}
\usepackage{verbatim}
\usepackage{enumitem}

\usepackage{hyperref}
\hypersetup{
    colorlinks = true,
    allcolors = Brown,
}

\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{hyphenat}
\usepackage{fontawesome}
\usepackage{ragged2e}
\usepackage[super]{nth}
\usepackage{expl3}



\ExplSyntaxOn
% Define the custom command
\NewDocumentCommand{\customcommand}{mm}{
    \int_zero:N \l_tmpa_int % Reset the counter
    % Parse the input lists
    \seq_set_split:Nnn \l_tmpa_seq { , } { #1 } % First list
    \seq_set_split:Nnn \l_tmpb_seq { , } { #2 } % Second list

    % Ensure both lists have the same length
    \int_compare:nNnTF {\seq_count:N \l_tmpa_seq} = {\seq_count:N \l_tmpb_seq}
        {
            % If lengths match, generate hyperlinks
          [\seq_mapthread_function:NNN \l_tmpa_seq \l_tmpb_seq \__customcommand_generate_hyperlink:nn]
        }
        {
            % If lengths don't match, throw an error
            \textbf{Error: Lists must have the same length!}
        }
}

\cs_new_protected:Nn \__customcommand_generate_hyperlink:nn {
    \int_incr:N \l_tmpa_int % Increment the counter
    \hyperlink{#1}{#2}%
    % Add a comma and space unless this is the last item
    \int_compare:nNnT {\l_tmpa_int} < {\seq_count:N \l_tmpa_seq}
        {,~}
}

\ExplSyntaxOff


\input{glyphtounicode}

\newcommand*{\doi}[1]{\href{http://dx.doi.org/#1}{doi:#1}}
\newcommand*{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}
\newcommand*{\biorxiv}[1]{\href{http://biorxiv.org/content/#1}{bioRxiv:#1}}
\newcommand*{\pubmed}[1]{\href{http://www.ncbi.nlm.nih.gov/pubmed/#1}{PMID:#1}}


%---------- FONT OPTIONS ----------
% sans-serif
% \usepackage[sfdefault]{FiraSans}
% \usepackage[sfdefault]{roboto}
% \usepackage[sfdefault]{noto-sans}
% \usepackage[default]{sourcesanspro}

% serif
% \usepackage{CormorantGaramond}
\usepackage[T1]{fontenc}
\usepackage[bitstream-charter]{mathdesign}


\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
% \addtolength{\oddsidemargin}{-0.5in}
% \addtolength{\evensidemargin}{-0.5in}
% \addtolength{\textwidth}{1in}
% \addtolength{\topmargin}{-.5in}
% \addtolength{\textheight}{1.0in}
\addtolength{\oddsidemargin}{-0.25in}
\addtolength{\evensidemargin}{-0.25in}
\addtolength{\textwidth}{0.5in}
\addtolength{\topmargin}{-.5in}
\addtolength{\textheight}{1.0in}

\urlstyle{same}

\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Sections formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]


\newcommand{\dualsectionold}[2]{%
  \noindent
    \parbox[b]{0.5\textwidth}{\raggedright\scshape\large #1}%
    \hfill
    \parbox[b]{0.5\textwidth}{\raggedleft\scshape\large #2}%
}
\newcommand{\dualsectionhline}{%
  \vspace{2pt}\color{black}\titlerule\vspace{-5pt}
}
  
\newcommand{\dualsection}[2]{%
  \dualsectionold{#1}{#2}%
  \vspace{-5pt}\dualsectionhline
}

% Ensure that generate pdf is machine readable/ATS parsable
\pdfgentounicode=1

%-------------------------
% Custom commands

\newcommand{\resumeItem}[1]{
  \item\small{
    {#1 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubSubheading}[2]{
    \vspace{-2pt}\item
    \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
      \textit{\small#1} & \textit{\small #2} \\
    \end{tabular*}\vspace{-7pt}
}


\newcommand{\resumeSubheading}[5]{
  \vspace{-2pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & #2 \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}
        \ifx\relax#5\relax 
          \vspace{-7pt}
        \else
          \linebreak\textit{\small#5}
          \vspace{-3pt}
        \fi
}

\newcommand{\simpleHeading}[3]{
  \vspace{-2pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{\small#1} & \small#2 \\
    \end{tabular*}
    \ifx\relax#3\relax 
    \else
      \linebreak\textit{\small#3}
    \fi
    \vspace{-5pt}
}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.10in, rightmargin=0.10in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

\begin{document}
\justifying

\begin{center}
  \textbf{\Huge \scshape Jason Ken Adhinarta} \\ \vspace{3pt}
    \small
    \href{https://jasonkena.github.io}{jasonkena.github.io}
   \hspace{0.05cm}$\cdot$\hspace{0.05cm}
    \href{mailto:jason.adhinarta@bc.edu}{ jason.adhinarta@bc.edu }
   \hspace{0.05cm}$\cdot$\hspace{0.05cm}
    Chestnut Hill, MA
\end{center}


\dualsection{Statement of Purpose}{University of California Berkeley}
\vspace{2pt}\color{black}\titlerule%\vspace{-5pt}

Emmerich Research Center was located in the same building as a tutoring center in Jakarta, Indonesia. The lab members there juggled responsibilities as both scientists and teachers; one day rigging conveyor-belt-mounted webcams to monitor larval growth and another helping kids design heat-seeking autonomous cars to extinguish candles. Who wouldn't be intrigued?

In high school, as an intern for the lab, I learned how to code by designing temperature control systems for vacuum chambers, and was introduced to computer vision while attempting to calculate reaction rates from video footage of our weighing scales. These early experiences sparked a fascination with the machine learning methods used to accelerate progress in biomedical fields. Looking ahead, I believe that pursuing a \textbf{PhD in Computer Science at UC Berkeley} will prepare me for a research career focused on developing \textbf{computer vision techniques that are widely applicable across neuroscience and medicine.}

A few weeks into my freshman year at Boston College, I applied to work at Prof.\ Donglai Wei’s Computer Vision Lab. Having prior experience with computer vision techniques in interdisciplinary settings, I was intrigued by the lab’s specialization in \textbf{connectomics}---a field focused on \textbf{reconstructing the brain’s wiring diagram from small samples of tissue imaged at nanometer resolutions}. Over the course of a few months navigating the literature, acquainting myself with the PyTorch Connectomics codebase, and figuring out how to submit SLURM jobs on the Boston College Linux Cluster, connectomics was demystified ever so slightly.

Through my first research project at the lab, I was introduced to Shixuan Gu, who was then a master’s student at Carnegie Mellon University. He hypothesized that the Frenet-Serret formulas from differential geometry could be used to improve the detection of aneurysms and synaptic connections by “straightening” blood vessel and dendrite geometries before they are fed into machine learning models. After I implemented and ran experiments for dendritic spine segmentation, we hastily prepared a manuscript detailing how enforcing this equivariance allowed our \textbf{point cloud models} to maintain high performance with \textbf{significantly less data and fewer augmentations} on our datasets. Despite my eagerness to land my first deep learning publication, our submission was rejected at MICCAI 2023.

Taking feedback from the rebuttal to heart, I evaluated the performance of modern point cloud architectures, implemented 5-fold cross-validation across our benchmarks, and manually inspected our annotations for the 4,476 dendritic spines we had. I performed detailed analyses studying how our transform induced cross-domain generalization---allowing models trained on the dendrites in the mouse somatosensory cortex to demonstrate \textbf{strong zero-shot performance on structures in the mouse visual cortex and human frontal lobe}. We submitted the manuscript to IEEE Transactions on Medical Imaging last month \customcommand{freseg}{D}. While I hope to do work that accelerates scientific progress, this project taught me that proper science is “slow,” requiring meticulous attention to detail and the humility to recognize mistakes.

During the summer of 2023, I was awarded a \$4,800 stipend by the Boston College Eagle Intern Fellowship, which gave me the opportunity to branch out into \textbf{biomedical imaging} as an intern at the EPFL CVLab in Switzerland. Under the guidance of Dr.\ Jiancheng Yang and Prof.\ Pascal Fua, I contributed to the \textbf{Heart Augmented Reality Training System}, which aimed to develop a \textbf{surgery simulator for practicing catheter insertion}. The setup involved a simple box equipped with cameras to track catheter movements, which were mapped onto a 3D heart model displayed on screen, providing a more interactive training experience.

Sitting across from two PhD students, I gained valuable insights into their work on applying neural fields to novel view synthesis and implicit surface representation problems. Incorporating what I had learned, I was tasked with integrating transformers pretrained on the TotalSegmentator organ segmentation dataset with Dr.\ Yang’s prior work on \textbf{latent-conditioned shape templates}---in order to \textbf{generate anatomically correct heart models from patients’ MRI scans}. This work was published at the International Conference on Medical Image Computing and Computer Assisted Intervention 2024 \customcommand{imheart}{G}. Besides showing me how integral the exchange of ideas is to the research process, the internship allowed me to see that machine learning tools were not merely academic, having real promise in improving patient outcomes.

I am currently working on three projects: enhancing the PyTorch Connectomics framework using segmentation-guided contrastive learning foundation models, clustering neurons in fresh-water polyps \customcommand{hydra_bio}{B} using translation and rotation equivariant autoencoders \customcommand{hydra}{A}, and adapting cell tracking solutions to extract whole-brain neural dynamics in roundworms \customcommand{wormnd}{C}.

During my PhD, I aim to continue my research on improving \textbf{computer vision} models. My previous work on multi-seed tracking schemes---which adapt the Segment Anything Model (SAM) for volumetric microscopy images \customcommand{trisam}{E}---closely aligns with \textbf{Prof.\ Avideh Zakhor’s} research leveraging SAM to detect invasive melanoma. In addition, I have extensive experience training point cloud architectures to process dendrites in 3D microscopy \customcommand{freseg}{D} and rib cage structures in CT scans \customcommand{ribseg}{H}. This should naturally translate to the \textbf{Video and Image Processing Lab’s} line of work on LiDAR scans.

On the \textbf{neuroscience} side of things, my past research has largely focused on developing segmentation models for dendrites \customcommand{freseg}{D}, synaptic vesicles \customcommand{hydra,hydra_bio,xiaomeng}{A,B,F}, and cerebral vasculature \customcommand{freseg,trisam}{D,E}. Last summer, I expanded on this work by developing benchmarks for neural activity trace extraction to promote progress in reverse engineering the nervous system of \textit{C.\ elegans} \customcommand{wormnd}{C}. Going forward, I hope to branch out and study how machine learning can decode representations of concepts and intents in neural activity. \textbf{Prof.\ Jack Gallant’s} recent work on spatiotemporal autoencoders to facilitate the interpretation of fMRI data is particularly interesting to me. I am also open to exploring the applications of brain-machine interfaces in clinical settings and would be interested in learning about \textbf{Prof.\ Preeya Khanna’s} research using neurofeedback to aid patients with Parkinson’s disease.

I believe that my interdisciplinary background, spanning diverse geometric representations, imaging modalities, and biomedical applications, has uniquely prepared me to contribute to rigorous research at UC Berkeley.


\section{References \textit{\small{(* indicates equal contribution)}}}
\vspace{3pt}
\resumeSubHeadingListStart
    \small{\item{
        
        \samepage{
          \hypertarget{hydra}{
            [A]
          }
          \textbf{Jason K. Adhinarta}*, Yutian Fan*, Michael Lin*, Richard Ren*, Micaela Roth*, Ayal Yakobe*, Shulin Zhang*, Rafael Yuste, Donglai Wei. \textbf{VesicleEM: A Comprehensive Vesicle Analysis Toolbox for Volumetric Electron Microscopy}. 
          \ifx\relaxManuscript in preparation\relax % Check if #5 is defined (empty)
          \else
            Manuscript in preparation.        
          \fi
           
         }
        
        \samepage{
          \hypertarget{hydra_bio}{
            [B]
          }
          Shulin Zhang, Netanel Ofer, Wataru Yamomoto, Richard Schalek, Yuelong Wu, Christoph Dupre, \textbf{Jason K. Adhinarta}, Yutian Fan, Michael Lin, Micaela Roth, Ben Cox, Celina Juliano, Donglai Wei, Jeff Lichtman, Rafael Yuste. \textbf{Connectomic analysis of the \textit{Hydra vulgaris} endoderm: cell types and vesicles}. 
          \ifx\relaxManuscript in preparation\relax % Check if #5 is defined (empty)
          \else
            Manuscript in preparation.        
          \fi
           
         }
        
        \samepage{
          \hypertarget{wormnd}{
            [C]
          }
          \textbf{Jason K. Adhinarta}*, Jizheng Dong*, Tianxiao He*, Junxiang Huang*, Daniel Sprague*, Jia Wan, Hyun Jee Lee, Zikai Yu, Hang Lu, Eviatar Yemini, Saul Kato, Erdem Varol, Donglai Wei. \textbf{WormND: A Benchmark for Extracting Whole-Brain Neural Dynamics of \textit{C. elegans} at the Neuron Resolution}. 
          \ifx\relaxManuscript under revision\relax % Check if #5 is defined (empty)
          \else
            Manuscript under revision.        
          \fi
           
         }
        
        \samepage{
          \hypertarget{freseg}{
            [D]
          }
          Shixuan Gu, \textbf{Jason K. Adhinarta}, Mikhail Bessmeltsev, Jiancheng Yang, Jessica Zhang, Wenjie Yin, Daniel Berger, Jeff W. Lichtman, Hanspeter Pfister, Donglai Wei. \textbf{Frenet-Serret Frame-based Decomposition for Part Segmentation of 3D Curvilinear Structures}. 
          \ifx\relaxUnder review at IEEE Transactions on Medical Imaging\relax % Check if #5 is defined (empty)
          \else
            Under review at IEEE Transactions on Medical Imaging.        
          \fi
           \arxiv{2404.14435}
         }
        
        \samepage{
          \hypertarget{trisam}{
            [E]
          }
          Jia Wan, Wanhua Li, \textbf{Jason K. Adhinarta}, Atmadeep Banerjee, Evelina Sjostedt, Jingpeng Wu, Jeff Lichtman, Hanspeter Pfister, Donglai Wei. \textbf{TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images}. 
          \ifx\relaxUnder review at IEEE Journal of Biomedical and Health Informatics\relax % Check if #5 is defined (empty)
          \else
            Under review at IEEE Journal of Biomedical and Health Informatics.        
          \fi
           \arxiv{2401.13961v4}
         }
        
        \samepage{
          \hypertarget{xiaomeng}{
            [F]
          }
          Xiaomeng Han, Xiaotang Lu, Peter H. Li, Shuohong Wang, Richard Schalek, Yaron Meirovitch, Zudi Lin, \textbf{Jason K. Adhinarta}, Daniel Berger, Yuelong Wu, Tao Fang, Elif S. Meral, Shadnan Asraf, Hidde Ploegh, Hanspeter Pfister, Donglai Wei, Viren Jain, James S. Trimmer, Jeff W. Lichtman. \textbf{Multiplexed Volumetric CLEM enabled by antibody derivatives provides new insights into the cytology of the mouse cerebellar cortex}. 
          \ifx\relaxNature Communications 2024\relax % Check if #5 is defined (empty)
          \else
            Nature Communications 2024.        
          \fi
           \doi{10.1038/s41467-024-50411-z} \pubmed{39103318}
         }
        
        \samepage{
          \hypertarget{imheart}{
            [G]
          }
          Jiancheng Yang, Ekaterina Sedykh, \textbf{Jason K. Adhinarta}, Hieu Le, Pascal Fua. \textbf{Generating Anatomically Accurate Heart Structures via Neural Implicit Fields}. 
          \ifx\relaxMedical Image Computing and Computer-Assisted Intervention 2024\relax % Check if #5 is defined (empty)
          \else
            Medical Image Computing and Computer-Assisted Intervention 2024.        
          \fi
           \doi{10.1007/978-3-031-72378-0\_25}
         }
        
        \samepage{
          \hypertarget{ribseg}{
            [H]
          }
          Liang Jin, Shixuan Gu, Donglai Wei, \textbf{Jason K. Adhinarta}, Kaiming Kuang, Yongjie J. Zhang, Hanspeter Pfister, Bingbing Ni, Jiancheng Yang, Ming Li. \textbf{RibSeg v2: A Large-scale Benchmark for Rib Labeling and Anatomical Centerline Extraction}. 
          \ifx\relaxIEEE Transactions on Medical Imaging 2023\relax % Check if #5 is defined (empty)
          \else
            IEEE Transactions on Medical Imaging 2023.        
          \fi
           \doi{10.1109/TMI.2023.3313627} \pubmed{37695967}
         }
        
    }}
\resumeSubHeadingListEnd




\end{document}
